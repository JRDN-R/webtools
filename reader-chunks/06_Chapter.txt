Backend AI Server (Python): A Python server (e.g., using Flask or FastAPI) receives the message. It uses a local Hugging Face DistilGPT-2 model to preprocess or generate context for the prompt, and it incorporates relevant RAG (Retrieval-Augmented Generation) context (family details) from a vector database. It then calls the OpenAI o3 API with a crafted prompt (including a system instruction for humor style and any retrieved context).