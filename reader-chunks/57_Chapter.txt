The entire round-trip should only take a couple of seconds in practice. Most latency comes from the OpenAI API call. Using the local GPT-2 is fast (milliseconds) and the embedding lookup is also quick.